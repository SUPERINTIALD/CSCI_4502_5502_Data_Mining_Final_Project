import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import statsmodels.api as sm
import warnings
# warnings.filterwarnings("ignore")

from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.tsa.arima.model import ARIMA
from sklearn.metrics import mean_squared_error
from math import sqrt

# Configure plots
plt.style.use('ggplot')


# #We will be only using ZHVI datasets for timeseries for housing prices
# filePath_ZHVI = {
#     "updated-zillow-price/HomeValues(ZHVI)/City_ZHVI_1bedroom_time_series.csv",
#     # "updated-zillow-price/HomeValues(ZHVI)/City_ZHVI_2bedroom_time_series.csv",
#     "updated-zillow-price/HomeValues(ZHVI)/City_ZHVI_3bedroom_time_series.csv",
#     "updated-zillow-price/HomeValues(ZHVI)/City_ZHVI_4bedroom_time_series.csv",
#     "updated-zillow-price/HomeValues(ZHVI)/City_ZHVI_5+bedroom_time_series.csv",
#     "updated-zillow-price/HomeValues(ZHVI)/City_ZHVI_All_Homes_Bottom_tier_time_series.csv",
#     "updated-zillow-price/HomeValues(ZHVI)/City_ZHVI_All_Homes_Top_tier_time_series.csv",
#     "updated-zillow-price/HomeValues(ZHVI)/City_ZHVI_Condo-Co-op_time_series.csv",
#     "updated-zillow-price/HomeValues(ZHVI)/City_ZHVI_Single_Family_Homes_time_series.csv",
#     "updated-zillow-price/HomeValues(ZHVI)/City_ZHVI_Single_Family_Residence_smoothAdjusted.csv"
# }

# filePath_Sale_Listing = {
#     "updated-zillow-price/For_Sale_Listings/Metro_US_NewlyPendingListings(Smooth,Allhomes,monthly).csv"
# }

# filePath_ZORI = {
#     "updated-zillow-price/Rental(ZORI)/City_ZORI_All_Homes_Plus_Mutlifamily_time_series_(smoothed-seasonallyAdjusted).csv",
#     "updated-zillow-price/Rental(ZORI)/City_ZORI_All_Homes_Plus_Mutlifamily_time_series_(smoothed).csv"
# }

# filePathSalePrice = {
#     "updated-zillow-price/Sales_Price/Metro_US_Mean_Sale_Price_(Smooth,SeasonallyAdjusted,All_Homes,Monthly).csv",
#     "updated-zillow-price/Sales_Price/Metro_US_Mean_Sale_to_List_Ratio_(Smooth,All_Homes,Monthly).csv",
#     "updated-zillow-price/Sales_Price/Metro_US_Median_Sale_Price_(Smooth,SeasonallyAdjusted,All_Homes,Monthly).csv",
#     "updated-zillow-price/Sales_Price/Metro_US_Median_Sale_to_List_Ratio_(Smooth,All_Homes,Monthly).csv",
#     "updated-zillow-price/Sales_Price/Metro_US_Percent_of_Homes_Sold_Above_List_(Smooth,AllHomes,Monthly).csv",
#     "updated-zillow-price/Sales_Price/Metro_US_Percent_of_Homes_Sold_Below_List_(Smooth,AllHomes,Monthly).csv",
#     "updated-zillow-price/Sales_Price/Metro_US_Total_Transaction_Value_(Smooth,SeasonallyAdjusted,All_Homes,Monthly).csv",
#     "updated-zillow-price/Sales_Price/Sales_Count_Nowcast_(Raw,All_Homes).csv"
# }

# fileHeatIndex = "updated-zillow-price/Market_Heat_Index/Metro_US_Market_Heat_Index_(AllHomes,Monthly).csv"

# filePathPriceCut = {
#     "updated-zillow-price/Days_On_Market_and_Price_cuts/Metro_US_Mean_Days_to_Close_(Smooth, AllHomes, Monthly).csv",
#     "updated-zillow-price/Days_On_Market_and_Price_cuts/Metro_US_Mean_Days_to_Pending_(Smooth, AllHomes, Monthly).csv",
#     "updated-zillow-price/Days_On_Market_and_Price_cuts/Metro_US_Mean_Price_Cut_(%,Smoothed,AllHomes,Monthly).csv",
#     "updated-zillow-price/Days_On_Market_and_Price_cuts/Metro_US_Mean_Price_Cut_($,Smoothed,AllHomes,Monthly).csv",
#     "updated-zillow-price/Days_On_Market_and_Price_cuts/Metro_US_Median_Days_to_Close_(Smooth, AllHomes, Monthly).csv",
#     "updated-zillow-price/Days_On_Market_and_Price_cuts/Metro_US_Median_Days_to_Pending_(Smooth, AllHomes, Monthly).csv",
#     "updated-zillow-price/Days_On_Market_and_Price_cuts/Metro_US_Median_Price_Cut_(%,Smoothed,AllHomes,Monthly).csv",
#     "updated-zillow-price/Days_On_Market_and_Price_cuts/Metro_US_Median_Price_Cut_($,Smoothed,AllHomes,Monthly).csv"
# }


# Define file paths for Bottom Tier and Top Tier datasets
file_paths = {
    "Bottom_Tier": "updated-zillow-price/HomeValues(ZHVI)/City_ZHVI_All_Homes_Bottom_tier_time_series.csv",
    "Top_Tier": "updated-zillow-price/HomeValues(ZHVI)/City_ZHVI_All_Homes_Top_tier_time_series.csv"
}


# Load the data and preview it
bottom_tier_df = pd.read_csv(file_paths["Bottom_Tier"])
top_tier_df = pd.read_csv(file_paths["Top_Tier"])

# Display the first few rows of each dataset
print("Bottom Tier Data:")
display(bottom_tier_df.head())

print("\nTop Tier Data:")
display(top_tier_df.head())


# Function to filter the dataset for Boulder, CO
def filter_boulder_data(df):
    # Filter for Boulder, CO
    boulder_data = df[(df["RegionName"] == "Boulder") & (df["State"] == "CO")]
    
    # If no data found
    if boulder_data.empty:
        print("No data found for Boulder, CO.")
        return None

    # Extract columns that match the time-series format (e.g., 'YYYY-MM-DD' or 'YYYY-MM')
    date_columns = boulder_data.columns[7:]
    valid_date_columns = [col for col in date_columns if col.startswith("20")]
    
    # Create time-series data
    time_series = boulder_data[valid_date_columns].T  # Transpose to get time-series
    time_series.columns = ["Price"]  # Set column name
    time_series.index = pd.to_datetime(valid_date_columns, format='%Y-%m-%d', errors='coerce')  # Explicit format
    return time_series

# Filter data for Boulder, CO in Bottom Tier and Top Tier datasets
boulder_bottom_tier = filter_boulder_data(bottom_tier_df)
boulder_top_tier = filter_boulder_data(top_tier_df)

# Display the filtered Boulder time-series data
print("Boulder Bottom Tier Time-Series Data:")
print(boulder_bottom_tier.head())

print("\nBoulder Top Tier Time-Series Data:")
print(boulder_top_tier.head())




# Plot the data
plt.figure(figsize=(12, 6))
plt.plot(boulder_bottom_tier.index, boulder_bottom_tier["Price"], label="Bottom Tier Prices", linewidth=2)
plt.plot(boulder_top_tier.index, boulder_top_tier["Price"], label="Top Tier Prices", linewidth=2)
plt.title("Boulder Housing Prices Over Time")
plt.xlabel("Year")
plt.ylabel("Price (USD)")
plt.legend()
plt.grid(True)
plt.show()


from statsmodels.tsa.stattools import adfuller

# Function to perform ADF test
#Use this to check if time-series is stationary... Its essentail for ARIMA/SARIMA because models assume that statistical properties (mean, variance, autocorrelation) of time series don't change over time
def check_stationarity(time_series):
    result = adfuller(time_series["Price"])
    print(f"ADF Statistic: {result[0]}")
    print(f"p-value: {result[1]}")
    print("Critical Values:")
    for key, value in result[4].items():
        print(f"   {key}: {value}")
    if result[1] < 0.05:
        print("The data is stationary.")
    else:
        print("The data is not stationary.")

# Check stationarity for Bottom Tier and Top Tier
print("Bottom Tier Stationarity Check:")
check_stationarity(boulder_bottom_tier)
print("\nTop Tier Stationarity Check:")
check_stationarity(boulder_top_tier)



#Since not stationary, since p-values were greater than 0.05, ADF were not less than critical values
# To make data stationary, we need to apply transformations to remove the trend and stabilize variance.
# WE did differening: Subtract each data point from previous point to remove trends
# This made teh series fluctuate around constant mean

# Apply first-order differencing
boulder_bottom_tier_diff = boulder_bottom_tier.diff().dropna()
boulder_top_tier_diff = boulder_top_tier.diff().dropna()

# Re-run the ADF test
print("Bottom Tier Stationarity Check After Differencing:")
check_stationarity(boulder_bottom_tier_diff)

print("\nTop Tier Stationarity Check After Differencing:")
check_stationarity(boulder_top_tier_diff)









from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
import matplotlib.pyplot as plt

# Plot ACF and PACF for Bottom Tier
print("ACF and PACF for Bottom Tier:")
plot_acf(boulder_bottom_tier_diff, lags=50)
plt.title("Bottom Tier ACF")
plt.show()

plot_pacf(boulder_bottom_tier_diff, lags=50)
plt.title("Bottom Tier PACF")
plt.show()

# Plot ACF and PACF for Top Tier
print("ACF and PACF for Top Tier:")
plot_acf(boulder_top_tier_diff, lags=50)
plt.title("Top Tier ACF")
plt.show()

plot_pacf(boulder_top_tier_diff, lags=50)
plt.title("Top Tier PACF")
plt.show()






# Recalculate the differenced datasets
bottom_tier_diff = boulder_bottom_tier["Price"].diff().dropna()
top_tier_diff = boulder_top_tier["Price"].diff().dropna()

# Define ARIMA parameters based on earlier observations
bottom_tier_params = (2, 1, 1)  # p=2, d=1, q=1
top_tier_params = (2, 1, 1)

# Fit ARIMA models for Bottom Tier and Top Tier
bottom_tier_arima = ARIMA(bottom_tier_diff, order=bottom_tier_params).fit()
top_tier_arima = ARIMA(top_tier_diff, order=top_tier_params).fit()

# Print summaries of the fitted ARIMA models
print("Bottom Tier ARIMA Model Summary:")
print(bottom_tier_arima.summary())
print("\nTop Tier ARIMA Model Summary:")
print(top_tier_arima.summary())






from statsmodels.tsa.arima.model import ARIMA
import matplotlib.pyplot as plt
import numpy as np

# Refit the ARIMA models for both Bottom Tier and Top Tier
bottom_tier_model = ARIMA(bottom_tier_diff, order=(2, 1, 1)).fit()
top_tier_model = ARIMA(top_tier_diff, order=(2, 1, 1)).fit()

# Display model summaries
print("Bottom Tier ARIMA Model Summary:")
print(bottom_tier_model.summary())

print("\nTop Tier ARIMA Model Summary:")
print(top_tier_model.summary())



# Plot residuals for Bottom Tier
bottom_tier_residuals = bottom_tier_model.resid
plt.figure(figsize=(12, 6))
plt.subplot(2, 1, 1)
plt.plot(bottom_tier_residuals, label="Residuals")
plt.axhline(0, color='red', linestyle='--')
plt.title("Bottom Tier ARIMA Residuals")
plt.legend()

# Histogram of residuals
plt.subplot(2, 1, 2)
plt.hist(bottom_tier_residuals, bins=30, edgecolor='k')
plt.title("Bottom Tier Residuals Histogram")
plt.tight_layout()
plt.show()

# Plot residuals for Top Tier
top_tier_residuals = top_tier_model.resid
plt.figure(figsize=(12, 6))
plt.subplot(2, 1, 1)
plt.plot(top_tier_residuals, label="Residuals")
plt.axhline(0, color='red', linestyle='--')
plt.title("Top Tier ARIMA Residuals")
plt.legend()

# Histogram of residuals
plt.subplot(2, 1, 2)
plt.hist(top_tier_residuals, bins=30, edgecolor='k')
plt.title("Top Tier Residuals Histogram")
plt.tight_layout()
plt.show()



# Reintegrate Bottom Tier Forecast
forecast_bottom = bottom_tier_model.get_forecast(steps=12)
forecast_bottom_diff = forecast_bottom.predicted_mean
forecast_bottom_index = pd.date_range(start=bottom_tier.index[-1] + pd.offsets.MonthEnd(), periods=12, freq="ME")

# Convert differenced forecast to original scale
forecast_bottom_reintegrated = forecast_bottom_diff.cumsum() + bottom_tier.iloc[-1]

# Reintegrate confidence intervals
forecast_bottom_ci = forecast_bottom.conf_int()
forecast_bottom_ci_reintegrated = forecast_bottom_ci.cumsum() + bottom_tier.iloc[-1]

# Reintegrate Top Tier Forecast
forecast_top = top_tier_model.get_forecast(steps=12)
forecast_top_diff = forecast_top.predicted_mean
forecast_top_index = pd.date_range(start=top_tier.index[-1] + pd.offsets.MonthEnd(), periods=12, freq="ME")

# Convert differenced forecast to original scale
forecast_top_reintegrated = forecast_top_diff.cumsum() + top_tier.iloc[-1]

# Reintegrate confidence intervals
forecast_top_ci = forecast_top.conf_int()
forecast_top_ci_reintegrated = forecast_top_ci.cumsum() + top_tier.iloc[-1]

# Plot Forecasts for Bottom Tier
plt.figure(figsize=(14, 8))
plt.plot(bottom_tier, label="Observed Bottom Tier Prices")
plt.plot(forecast_bottom_index, forecast_bottom_reintegrated, label="Forecasted Prices", color="red")
plt.fill_between(forecast_bottom_index,
                 forecast_bottom_ci_reintegrated.iloc[:, 0],
                 forecast_bottom_ci_reintegrated.iloc[:, 1],
                 color="pink", alpha=0.3)
plt.title("Bottom Tier Housing Price Forecast")
plt.legend()
plt.show()

# Plot Forecasts for Top Tier
plt.figure(figsize=(14, 8))
plt.plot(top_tier, label="Observed Top Tier Prices")
plt.plot(forecast_top_index, forecast_top_reintegrated, label="Forecasted Prices", color="blue")
plt.fill_between(forecast_top_index,
                 forecast_top_ci_reintegrated.iloc[:, 0],
                 forecast_top_ci_reintegrated.iloc[:, 1],
                 color="lightblue", alpha=0.3)
plt.title("Top Tier Housing Price Forecast")
plt.legend()
plt.show()






import pandas as pd
import matplotlib.pyplot as plt

# Define forecasting horizons (5, 10, 15, 20 years)
forecast_years = [5, 10, 15, 20]
steps_per_year = 12  # Monthly data, so 12 steps per year

# Function to forecast and re-integrate
def forecast_future(model, original_data, years, color, label):
    steps = years * steps_per_year  # Total forecast steps
    forecast = model.get_forecast(steps=steps)
    forecast_diff = forecast.predicted_mean
    
    # Generate future index
    future_index = pd.date_range(start=original_data.index[-1] + pd.offsets.MonthEnd(), periods=steps, freq="ME")
    
    # Convert differenced forecast to original scale
    forecast_reintegrated = forecast_diff.cumsum() + original_data.iloc[-1]
    
    # Reintegrate confidence intervals
    forecast_ci = forecast.conf_int()
    forecast_ci_reintegrated = forecast_ci.cumsum() + original_data.iloc[-1]
    
    # Plot forecast
    plt.plot(future_index, forecast_reintegrated, label=f"{label} {years}-Year Forecast", color=color)
    plt.fill_between(future_index,
                     forecast_ci_reintegrated.iloc[:, 0],
                     forecast_ci_reintegrated.iloc[:, 1],
                     color=color, alpha=0.2)

# Plot forecasts for Bottom Tier
plt.figure(figsize=(14, 8))
plt.plot(bottom_tier, label="Observed Bottom Tier Prices", color="black")
for i, years in enumerate(forecast_years):
    forecast_future(bottom_tier_model, bottom_tier, years, color=f"red", label="Bottom Tier")
plt.title("Bottom Tier Housing Price Forecast")
plt.legend()
plt.show()

# Plot forecasts for Top Tier
plt.figure(figsize=(14, 8))
plt.plot(top_tier, label="Observed Top Tier Prices", color="black")
for i, years in enumerate(forecast_years):
    forecast_future(top_tier_model, top_tier, years, color=f"blue", label="Top Tier")
plt.title("Top Tier Housing Price Forecast")
plt.legend()
plt.show()






from statsmodels.tsa.statespace.sarimax import SARIMAX

# Example: Fit a SARIMA model for Bottom Tier
seasonal_order = (1, 1, 1, 12)  # (P, D, Q, S) - seasonal order
sarima_bottom = SARIMAX(bottom_tier, order=(2, 1, 1), seasonal_order=seasonal_order).fit()
sarima_top = SARIMAX(top_tier, order=(2, 1, 1), seasonal_order=seasonal_order).fit()

# Print SARIMA summary
print("Bottom Tier SARIMA Model Summary:")
print(sarima_bottom.summary())
print("Top Tier SARIMA Model Summary:")
print(sarima_top.summary())




# Forecast with SARIMA for bottm tier
forecast_sarima = sarima_bottom.get_forecast(steps=60)  # 5 years ahead
forecast_sarima_mean = forecast_sarima.predicted_mean
forecast_sarima_ci = forecast_sarima.conf_int()
# Forecast with SARIMA for Top Tier (e.g., 5 years ahead = 60 months)
forecast_sarima_top = sarima_top.get_forecast(steps=60)
forecast_sarima_top_mean = forecast_sarima_top.predicted_mean
forecast_sarima_top_ci = forecast_sarima_top.conf_int()



# Plot SARIMA forecast
plt.figure(figsize=(14, 8))
plt.plot(bottom_tier, label="Observed Bottom Tier Prices")
plt.plot(forecast_sarima_mean.index, forecast_sarima_mean, label="SARIMA Forecast", color="red")
plt.fill_between(forecast_sarima_mean.index,
                 forecast_sarima_ci.iloc[:, 0],
                 forecast_sarima_ci.iloc[:, 1],
                 color="pink", alpha=0.3)
plt.title("Bottom Tier Housing Price SARIMA Forecast")

# Plot SARIMA forecast for Top Tier
plt.figure(figsize=(14, 8))
plt.plot(top_tier, label="Observed Top Tier Prices")
plt.plot(forecast_sarima_top_mean.index, forecast_sarima_top_mean, label="SARIMA Forecast", color="blue")
plt.fill_between(forecast_sarima_top_mean.index,
                 forecast_sarima_top_ci.iloc[:, 0],
                 forecast_sarima_top_ci.iloc[:, 1],
                 color="lightblue", alpha=0.3)
plt.title("Top Tier Housing Price SARIMA Forecast")


plt.legend()
plt.show()







